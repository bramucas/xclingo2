{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xclingo import XclingoControl\n",
    "xclingo_control = XclingoControl(\n",
    "    ['0'],  # internal clingo control arguments, 0 = \"all the models\"\n",
    "    n_explanations='0'  # Desired number of explanations per model, 0 = \"all the explanations\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_program = \"\"\"\n",
    "    person(gabriel;clare).\n",
    "\n",
    "    drive(gabriel).\n",
    "    alcohol(gabriel, 40).\n",
    "    resist(gabriel).\n",
    "\n",
    "    drive(clare).\n",
    "    alcohol(clare, 5).\n",
    "\n",
    "    %!trace_rule {\"% drove drunk\", P}.\n",
    "    punish(P) :- drive(P), alcohol(P,A), A>30, person(P).\n",
    "\n",
    "    %!trace_rule {\"% resisted to authority\", P}.\n",
    "    punish(P) :- resist(P), person(P).\n",
    "\n",
    "    %!trace_rule {\"% goes to prison\",P}.\n",
    "    sentence(P, prison) :- punish(P).\n",
    "\n",
    "    %!trace_rule {\"% is innocent by default\",P}.\n",
    "    sentence(P, innocent) :- person(P), not punish(P).\n",
    "\n",
    "    %!trace {alcohol(P,A), \"% alcohol's level is %\",P,A} :- alcohol(P,A).\n",
    "    %!trace {alcohol(P,A), \"% was drunk\",P} :- alcohol(P,A).\n",
    "\n",
    "    %!show_trace {sentence(P,S)} :- sentence(P,S).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xclingo_control.add('base', [], annotated_program)\n",
    "xclingo_control.ground([(\"base\", [])])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### xclingo models (XclingoModel)\n",
    "Calling solve on xclingo_control will yield `XclingoModel` objects.\n",
    "This object work as the usual `Model` class from clingo (it is, in fact, an extension to that class), but has an additional method to compute (and yield) the explanation graphs from that especific model: `explain_model()`.\n",
    "The objects yielded belong to the class `ExplanationGraphModel`.\n",
    "\n",
    "‼️‼️ Important: The explanation graphs will only be computed in the case you ask for one via calling `explain_model()`. The computing of the graphs is asynchronous, next explanation graph won't be computed until user asks for it.\n",
    "\n",
    "#### explanation graphs (ExplanationGraphModel)\n",
    "The objects yielded by `explain_model()`.\n",
    "The class is also an extension of clingo `Model`, and so it works as a usual model.\n",
    "However, the symbols in it represent the explanation of the model, and not the symbols from the model itself.\n",
    "The object additionally has a method `explain(self, symbol: Symbol)`, which retrieves the local explanation (object from `Explanation` class) for a symbol.\n",
    "The symbol the explanation is requested for has to be a node of the graph (in other words, it has to be true for the model being explained).\n",
    "\n",
    "#### explanations for a symbol (Explanation)\n",
    "`Explanation` is a tree-like object, where each object (node in the tree) may have from zero to many child explanations.\n",
    "Child nodes are accessed trough the `.causes` property.\n",
    "Each node has a `.labels` property, containing the text labels associated with the symbol for that explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Example: the actual xclingo code for explaining SATISFIABLE programs.\n",
    "nmodel = 0\n",
    "for x_model in xclingo_control.solve():\n",
    "    nmodel += 1\n",
    "    print(f\"Answer: {nmodel}\")\n",
    "    print(x_model)  # Prints a list of the true atoms for the model. Just like a usual Model object.\n",
    "    nexpl = 0\n",
    "    for graph_model in x_model.explain_model():\n",
    "        nexpl += 1\n",
    "        print(f\"##Explanation: {nmodel}.{nexpl}\")\n",
    "        for sym in graph_model.show_trace:\n",
    "            explanation = graph_model.explain(sym)\n",
    "            if explanation is not None:  # A symbol could have no explanation.\n",
    "                print(explanation)\n",
    "    print(f\"##Total Explanations:\\t{nexpl}\")\n",
    "if nmodel > 0:\n",
    "    print(f\"Models:\\t{nmodel}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the explanation will be presented as an ascii tree-like text, when printed.\n",
    "However, the objects have several methods to freely modify the explanation or to exploit it.\n",
    "Methods listed below:\n",
    "```python\n",
    "    def preorder_iterator(self, only_labelled=False) # Returns a “preorder” iterator over the explanation tree.\n",
    "    def ascii_tree(self) # Returns a tree-like string depicting the explanation.\n",
    "    def get_node_text(self) # “Gets” the text associated with a symbol for that explanation. Using all the labels.\n",
    "    def add_cause(self, cause) # “Adds” a new child explanation node for the current node.\n",
    "    def add_label(self, label) # “Adds” a new text label for the current symbol for that explanation.\n",
    "```\n",
    "\n",
    "As a very simple example, lets automatically translate the text in the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xclingo.explanation import Explanation\n",
    "from googletrans import Translator  # python3 -m pip install googletrans==3.1.0a0\n",
    "\n",
    "def translate_explanation(explanation: Explanation, destiny_lang=\"es\"):\n",
    "    translator = Translator()\n",
    "    for expl, depth_level in explanation.preorder_iterator(only_labelled=True):  # For each node, it replaces the labels with the translated text.\n",
    "        expl.labels = set([translator.translate(label, dest=destiny_lang).text for label in expl.labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 1\n",
      "person(gabriel) person(clare) alcohol(gabriel,40) alcohol(clare,5) drive(gabriel) drive(clare) punish(gabriel) resist(gabriel) sentence(clare,innocent) sentence(gabriel,prison)\n",
      "##Explanation: 1.1\n",
      "  *\n",
      "  |__\"clare es inocente por defecto\"\n",
      "\n",
      "  *\n",
      "  |__\"gabriel va a la carcel\"\n",
      "  |  |__\"Gabriel condujo borracho\"\n",
      "  |  |  |__\"el nivel de alcohol de gabriel es 40\";\"gabriel estaba borracho\"\n",
      "\n",
      "##Explanation: 1.2\n",
      "  *\n",
      "  |__\"clare es inocente por defecto\"\n",
      "\n",
      "  *\n",
      "  |__\"gabriel va a la carcel\"\n",
      "  |  |__\"Gabriel se resistió a la autoridad\"\n",
      "\n",
      "##Total Explanations:\t2\n",
      "Models:\t1\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "xclingo_control = XclingoControl(\n",
    "    ['0'],  # internal clingo control arguments, 0 = \"all the models\"\n",
    "    n_explanations='0'  # Desired number of explanations per model, 0 = \"all the explanations\"\n",
    ")\n",
    "xclingo_control.add('base', [], annotated_program)\n",
    "xclingo_control.ground([(\"base\", [])])\n",
    "\n",
    "nmodel = 0\n",
    "for x_model in xclingo_control.solve():\n",
    "    nmodel += 1\n",
    "    print(f\"Answer: {nmodel}\")\n",
    "    print(x_model)  # Prints a list of the true atoms for the model. Just like a usual Model object.\n",
    "    nexpl = 0\n",
    "    for graph_model in x_model.explain_model():\n",
    "        nexpl += 1\n",
    "        print(f\"##Explanation: {nmodel}.{nexpl}\")\n",
    "        for sym in graph_model.show_trace:\n",
    "            explanation = graph_model.explain(sym)\n",
    "            translate_explanation(explanation, destiny_lang=\"es\")\n",
    "            if explanation is not None:  # A symbol could have no explanation.\n",
    "                print(explanation)\n",
    "    print(f\"##Total Explanations:\\t{nexpl}\")\n",
    "if nmodel > 0:\n",
    "    print(f\"Models:\\t{nmodel}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xclingo-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
